\chapter{Conclusion and further work}
In this final chapter, we summarize our findings and look at interesting areas for further exploration.

\section{Conclusion}
In short, RNNs are very promising in the domain of session-based recommender systems. We have seen that they can compete with and outperform other state of the art models in this area. Deep learning also can be used to do most of the feature engineering work. This has awakened the interests for RNNs as recommender systems in big companies such as Zalando, who are looking into the practical application of such models \cite{ZALANDO:understanding-consumer-histories}. 

We have seen that there are several ways to improve the basic RNN recommender. One of the most interesting improvements is to utilize more information than just the item clicks. Timestamps can be used in two different ways. Using the time between actions in a session can help the recommender understand which actions are more or less relevant to each other. A long timespan between two actions might suggest that they are less relevant to each other, and that the RNN should forget much of what it know of the session. Time can also be used as an external context to the session. Time of day, day of week, month in the year, and whether it is a holiday, can further help the RNN to predict the most relevant items. Furthermore, additional information about both the action event and the corresponding item can be used. Often text or image is present and contains description of items. To use this efficiently, a good architecture must be chosen, and customized training can also help. We have looked at one such appropriate architecture, which used separate parallel GRU layers for the one-hot item encoding and the embedded description vector. Training the two GRU layers in an alternating fashion was shown to improve performance.

Different data augmentation techniques can also be helpful. One of the techniques was to pre-train the model on the full training set, and then fine-tune it on only the most recent examples. Intuitively this makes sense. We utilize the full training set, but focus the model on the most recent, up to date, examples. Older examples might contain trends that have later disappeared. 

News sites and other applications where items have a very short life cycle, the items in the training examples are not the same that will be recommended. Unless the model is retrained very frequently, but this requires a lot of fresh data. The solution in these situations can be to embed items into a denser space where items with similar features are close in the embedded space. The model can then ''recommend'' an embedding, and the actual recommendations can be found by finding items that are close to the recommendation in the embedded space.

In applications where items have a longer life-cycle, such as in many e-commerce sites, the problem is sometimes the large amount of items. The obvious solution is again to use embeddings. However, we have seen that this might reduce performance. 
 

\section{Further work}
There are two areas we want to look further into. First, improving the use of context information. In addition to using all the context and item information, we are interested in how we can use information from user actions that are not directly related to an item. E.g. search queries contain a lot of information about what the user is interested in, and should therefore be valuable information that can be utilized. 

Second, as the RNN processes a session, it learns an internal representation of the user-session. In the case were we have access to user identification, it could be possible to combine the user-session representations for a user to construct a dense representation of the user. We are interested in how this can be done, and if it can be used improve personalized recommendations.

%what is the future work
%have only looked at actions so fat
%we want to look at feeding in contextual data

%representation of the user

%- user representation with rnn (as the rnn works through a sequence, it stores a representation of user preferences, this could be used to represent the user. That is, the rnn creates a session representation and by combining these session representations for an individual user, it should be possible to represent the user.)
%- Use contextual information to improve the rnn recommender system