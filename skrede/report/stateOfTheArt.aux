\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{DBLP:journals/corr/Lipton15}
\citation{DBLP:journals/corr/Lipton15}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}State of the Art}{15}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chp:sota}{{2}{15}{State of the Art}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Other approaches}{15}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}The item-to-item approach}{15}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Markov models}{15}{subsection.2.1.2}}
\citation{Salakhutdinov:2007:RBM:1273496.1273596}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{DBLP:journals/corr/WangWY14}
\citation{Oord:2013:DCM:2999792.2999907}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{conf/recsys/WanLWGXC15}
\citation{Yu:2016:DRM:2911451.2914683}
\citation{Yu:2016:DRM:2911451.2914683}
\citation{Yu:2016:DRM:2911451.2914683}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Deep learning}{16}{subsection.2.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces General architecture of the RNN from ''A dynamic recurrent model for next basket recommendation'' by Yu et al. \cite  {Yu:2016:DRM:2911451.2914683}\relax }}{16}{figure.caption.6}}
\newlabel{fig:rnn-next-basket}{{2.1}{16}{General architecture of the RNN from ''A dynamic recurrent model for next basket recommendation'' by Yu et al. \cite {Yu:2016:DRM:2911451.2914683}\relax }{figure.caption.6}{}}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{dataset:recsys15}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Session-based recommendations with recurrent neural networks}{17}{section.2.2}}
\newlabel{sec:hidasi-sess-based-rnn}{{2.2}{17}{Session-based recommendations with recurrent neural networks}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces General architecture of the RNN from ''Session-based recommendations with recurrent neural networks''. \cite  {DBLP:journals/corr/HidasiKBT15}\relax }}{17}{figure.caption.7}}
\newlabel{fig:gru4rec-network}{{2.2}{17}{General architecture of the RNN from ''Session-based recommendations with recurrent neural networks''. \cite {DBLP:journals/corr/HidasiKBT15}\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Input layer}{18}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Embedding layer}{18}{subsection.2.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}GRU layers}{18}{subsection.2.2.3}}
\citation{Rendle:2009:BBP:1795114.1795167}
\citation{DBLP:journals/corr/HidasiKBT15}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Feedforward layers}{19}{subsection.2.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Training}{19}{subsection.2.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Evaluation metrics}{19}{subsection.2.2.6}}
\newlabel{sec:evaluation-metrics}{{2.2.6}{19}{Evaluation metrics}{subsection.2.2.6}{}}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{dataset:recsys15}
\citation{DBLP:journals/corr/HidasiKBT15}
\@writefile{toc}{\contentsline {subsubsection}{Recall@N}{20}{section*.8}}
\@writefile{toc}{\contentsline {subsubsection}{MRR@N}{20}{section*.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.7}Results and conclusion}{20}{subsection.2.2.7}}
\citation{DBLP:journals/corr/BrebissonSAVB15}
\citation{rnn-dropout}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/ChatfieldSVZ14}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Improving RNNs for session-based recommendations}{21}{section.2.3}}
\newlabel{sec:improved-rnn}{{2.3}{21}{Improving RNNs for session-based recommendations}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Data augmentation}{21}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Pre-training to adapt to temporal changes}{21}{subsection.2.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Data augmentation for training sequences as suggested in \cite  {DBLP:journals/corr/TanXL16}. Multiple training sequences are generated from the original sequence. Random dropout is applied to the clicks in the sequences.\relax }}{22}{figure.caption.10}}
\newlabel{fig:sequence-augmentation}{{2.3}{22}{Data augmentation for training sequences as suggested in \cite {DBLP:journals/corr/TanXL16}. Multiple training sequences are generated from the original sequence. Random dropout is applied to the clicks in the sequences.\relax }{figure.caption.10}{}}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{DBLP:journals/corr/HidasiKBT15}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Privileged information}{23}{subsection.2.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Data augmentation with teacher labels as suggested in \cite  {DBLP:journals/corr/TanXL16}. The student model is trained to predict a tradeoff between the real label and the label predicted by the teacher model. The label produced by the teacher model is the teacher model's prediction of the correct label but on the remainder of the sequence in reverse.\relax }}{23}{figure.caption.11}}
\newlabel{fig:rnn-teacher-student}{{2.4}{23}{Data augmentation with teacher labels as suggested in \cite {DBLP:journals/corr/TanXL16}. The student model is trained to predict a tradeoff between the real label and the label predicted by the teacher model. The label produced by the teacher model is the teacher model's prediction of the correct label but on the remainder of the sequence in reverse.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Output embeddings}{23}{subsection.2.3.4}}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{email:Hidasi}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Results and conclusion}{24}{subsection.2.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Results from \cite  {DBLP:journals/corr/TanXL16}. \textbf  {B} is the baseline, which is the reported performance from \cite  {DBLP:journals/corr/HidasiKBT15}. ''Plots of both evaluation metrics on models with GRU size 100 (left) and 1000 (right). The x-axis is logarithmic in dataset fraction, the rightmost point corresponds to the full dataset. M2 does not apply to the full dataset, and results for M3 on the larger GRU size were omitted'' \cite  {DBLP:journals/corr/TanXL16}\relax }}{24}{figure.caption.12}}
\newlabel{fig:improved-rnn-results}{{2.5}{24}{Results from \cite {DBLP:journals/corr/TanXL16}. \textbf {B} is the baseline, which is the reported performance from \cite {DBLP:journals/corr/HidasiKBT15}. ''Plots of both evaluation metrics on models with GRU size 100 (left) and 1000 (right). The x-axis is logarithmic in dataset fraction, the rightmost point corresponds to the full dataset. M2 does not apply to the full dataset, and results for M3 on the larger GRU size were omitted'' \cite {DBLP:journals/corr/TanXL16}\relax }{figure.caption.12}{}}
\citation{DBLP:journals/corr/LiuWWL016}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Utilizing context information}{25}{section.2.4}}
\citation{DBLP:journals/corr/TanXL16}
\citation{dataset:taobao}
\citation{dataset:movielens}
\citation{Song:2016:MDL:2911451.2914726}
\citation{Elkahky:2015:MDL:2736277.2741667}
\citation{Song:2016:MDL:2911451.2914726}
\citation{DBLP:journals/corr/TanXL16}
\citation{DBLP:journals/corr/TanXL16}
\citation{Twardowski:2016:MCI:2959100.2959162}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Multi-rate learning}{27}{section.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Modeling event information}{27}{section.2.6}}
\citation{Hidasi:2016:PRN:2959100.2959167}
\citation{DBLP:journals/corr/HidasiKBT15}
\citation{Hidasi:2016:PRN:2959100.2959167}
\citation{Hidasi:2016:PRN:2959100.2959167}
\citation{Hidasi:2016:PRN:2959100.2959167}
\citation{Hidasi:2016:PRN:2959100.2959167}
\citation{Hidasi:2016:PRN:2959100.2959167}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Parallell RNN for feature-rich sessions}{28}{section.2.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces One of the proposed architectures from \cite  {Hidasi:2016:PRN:2959100.2959167}. The image feature vector can be replaced with a text feature vector. f() is a nonlinearity applied to the output, in the paper they used tanh.\relax }}{29}{figure.caption.13}}
\newlabel{fig:parallell-rnn}{{2.6}{29}{One of the proposed architectures from \cite {Hidasi:2016:PRN:2959100.2959167}. The image feature vector can be replaced with a text feature vector. f() is a nonlinearity applied to the output, in the paper they used tanh.\relax }{figure.caption.13}{}}
\@setckpt{stateOfTheArt}{
\setcounter{page}{31}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{7}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{6}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{lstnumber}{1}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{41}
\setcounter{lstlisting}{0}
\setcounter{section@level}{1}
}
